{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.models import CrossEntropyClassification\n",
    "from src.data import train_val_test_split, get_descriptor_and_labels\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, RichProgressBar\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_type = \"steinhardt\"\n",
    "use_mda = True\n",
    "numb_train_samples = 8_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_structs, val_structs, test_structs = train_val_test_split(mda=use_mda,num_files=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1285, 20, 1245)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_structs), len(val_structs), len(test_structs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, label_mapping = get_descriptor_and_labels(train_structs, num_samples_per_type=numb_train_samples)\n",
    "val_x, val_y, _ = get_descriptor_and_labels(val_structs, num_samples_per_type=2_500)\n",
    "test_x, test_y, _ = get_descriptor_and_labels(test_structs, num_samples_per_type=2_500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hda': 0, 'lda': 1, 'mda': 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# fit to training data\n",
    "scaler = preprocessing.StandardScaler().fit(train_x)\n",
    "scaled_train_x = torch.FloatTensor(scaler.transform(train_x))\n",
    "scaled_val_x = torch.FloatTensor(scaler.transform(val_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(scaled_train_x,train_y)\n",
    "val_dataset = TensorDataset(scaled_val_x,val_y)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=250, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=10000, shuffle=False)\n",
    "\n",
    "output_size = train_y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from src.data import predict_test_set_classes\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "def optimise_NN(trial: optuna.Trial):\n",
    "    # Optuna optimisation function for the NN\n",
    "    \n",
    "    # 1. Suggest the hyperparameters\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 5)\n",
    "    neurons_per_layer = trial.suggest_int(\"n_units_l0\", 8, 128, log=True)\n",
    "    hidden_units = [neurons_per_layer] * n_layers\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-1, log=True)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    \n",
    "    input_size = 30\n",
    "\n",
    "    # 2. Create the model\n",
    "    model = CrossEntropyClassification(\n",
    "        input_size,\n",
    "        *hidden_units,\n",
    "        output_size,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "    )\n",
    "\n",
    "    # 3. Train the model\n",
    "    trainer = Trainer(\n",
    "        accelerator=\"auto\",\n",
    "        max_epochs=200,\n",
    "        callbacks=[\n",
    "            RichProgressBar(),\n",
    "            EarlyStopping(monitor=\"validation_loss\", patience=10),\n",
    "        ],\n",
    "        logger=TensorBoardLogger(\"lightning_logs\"),\n",
    "    )\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    \n",
    "    # 4. Load the best model\n",
    "    model.load_state_dict(torch.load(trainer.checkpoint_callback.best_model_path)['state_dict'])\n",
    "    \n",
    "    # 5. Evaluate the model\n",
    "    pred_classes, val_classes, _ = predict_test_set_classes(val_structs,model=model, scaler=scaler)\n",
    "    \n",
    "    return balanced_accuracy_score(val_classes, pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-30 14:22:34,884] Using an existing study with name 'optimise_NN' instead of creating a new one.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ activation │ ReLU       │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ layers     │ ModuleList │  2.1 K │\n",
       "└───┴────────────┴────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ activation │ ReLU       │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ layers     │ ModuleList │  2.1 K │\n",
       "└───┴────────────┴────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.1 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.1 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.1 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.1 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0df562274b24c4d8e9ef48ac23667f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/zoefaurebeaulieu/miniconda3/envs/steinhardt/lib/python3.10/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may \n",
       "be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus \n",
       "on this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/zoefaurebeaulieu/miniconda3/envs/steinhardt/lib/python3.10/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may \n",
       "be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus \n",
       "on this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/zoefaurebeaulieu/miniconda3/envs/steinhardt/lib/python3.10/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which \n",
       "may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of \n",
       "cpus on this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/zoefaurebeaulieu/miniconda3/envs/steinhardt/lib/python3.10/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which \n",
       "may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of \n",
       "cpus on this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "study_name = \"optimise_NN\"  # Unique identifier of the study.\n",
    "storage_name = f\"sqlite:///{study_name}.db\"\n",
    "study = optuna.create_study(study_name=study_name, storage=storage_name, direction=\"maximize\",load_if_exists=True)\n",
    "study.optimize(optimise_NN, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tet_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
